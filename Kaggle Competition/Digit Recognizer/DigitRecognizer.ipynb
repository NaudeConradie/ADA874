{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed = 42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.iloc[:, 1:]\n",
    "x_train = x_train.values.astype(np.float32).reshape(-1, 28*28) / 255\n",
    "x_valid, x_train = x_train[:4200], x_train[4200:]\n",
    "\n",
    "y_train = train_data.iloc[:, 0]\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_valid, y_train = y_train[:4200], y_train[4200:]\n",
    "\n",
    "x_test = test_data.values.astype(np.float32).reshape(-1, 28*28) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(x, y, batch_size):\n",
    "    rnd_i = np.random.permutation(len(x))\n",
    "    n_batches = len(x) // batch_size\n",
    "    \n",
    "    for batch_i in np.array_split(rnd_i, n_batches):\n",
    "        x_batch, y_batch = x[batch_i], y[batch_i]\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28\n",
    "w = 28\n",
    "channels = 1\n",
    "n_i = h*w\n",
    "n_o = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropoutrate = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 128\n",
    "fc1_dropoutrate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"inputs\"):\n",
    "    x = tf.placeholder(tf.float32, shape = [None, n_i], name = \"x\")\n",
    "    x_reshaped = tf.reshape(x, shape = [-1, h, w, channels])\n",
    "    y = tf.placeholder(tf.int32, shape = [None], name = \"y\")\n",
    "    training = tf.placeholder_with_default(False, shape = [], name = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-c0594e777e36>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From C:\\Users\\19673418\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(\n",
    "    x_reshaped, \n",
    "    filters = conv1_fmaps,\n",
    "    kernel_size = conv1_ksize,\n",
    "    strides = conv1_stride,\n",
    "    padding = conv1_pad,\n",
    "    activation = tf.nn.relu,\n",
    "    name = \"conv1\",\n",
    ")\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "    conv1, \n",
    "    filters = conv2_fmaps,\n",
    "    kernel_size = conv2_ksize,\n",
    "    strides = conv2_stride,\n",
    "    padding = conv2_pad,\n",
    "    activation = tf.nn.relu,\n",
    "    name = \"conv2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-8fd8e5fc2623>:15: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\Users\\19673418\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(\n",
    "        conv2,\n",
    "        ksize = [1, 2, 2, 1],\n",
    "        strides = [1, 2, 2, 1],\n",
    "        padding = \"VALID\",\n",
    "    )\n",
    "    pool3_flat = tf.reshape(\n",
    "        pool3,\n",
    "        shape = [-1, pool3_fmaps*14*14],\n",
    "    )\n",
    "    pool3_flat_drop = tf.layers.dropout(\n",
    "        pool3_flat,\n",
    "        conv2_dropoutrate,\n",
    "        training = training,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d16e0e07ba99>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(\n",
    "        pool3_flat_drop,\n",
    "        n_fc1,\n",
    "        activation = tf.nn.relu,\n",
    "        name = \"fc1\",\n",
    "    )\n",
    "    fc1_drop = tf.layers.dropout(\n",
    "        fc1,\n",
    "        fc1_dropoutrate,\n",
    "        training = training,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(\n",
    "        fc1,\n",
    "        n_o,\n",
    "        name = \"output\",\n",
    "    )\n",
    "    y_prob = tf.nn.softmax(\n",
    "        logits,\n",
    "        name = \"y_prob\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits = logits,\n",
    "        labels = y,\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameters():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {\n",
    "        gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model_parameters(model_parameters):\n",
    "    gvar_names = list(model_parameters.keys())\n",
    "    assign_ops = {\n",
    "        gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "        for gvar_name in gvar_names\n",
    "    }\n",
    "    init_values = {\n",
    "        gvar_name: assign_op.inputs[1]\n",
    "        for gvar_name, assign_op in assign_ops.items()\n",
    "    }\n",
    "    feed_dict = {\n",
    "        init_values[gvar_name]: model_parameters[gvar_name]\n",
    "        for gvar_name in gvar_names\n",
    "    }\n",
    "    tf.get_default_session().run(assign_ops, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_wo_progress = 20\n",
    "best_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "Epoch 0:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.0714%\n",
      "Validation set's best loss: 0.087169\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "Epoch 1:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.5476%\n",
      "Validation set's best loss: 0.050507\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "Epoch 2:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.2143%\n",
      "Validation set's best loss: 0.041257\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "Epoch 3:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.5952%\n",
      "Validation set's best loss: 0.036586\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "Epoch 4:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.6429%\n",
      "Validation set's best loss: 0.036586\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "Epoch 5:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.6190%\n",
      "Validation set's best loss: 0.036586\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "Epoch 6:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.7381%\n",
      "Validation set's best loss: 0.036586\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "Epoch 7:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9524%\n",
      "Validation set's best loss: 0.036586\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "Epoch 8:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.8333%\n",
      "Validation set's best loss: 0.036586\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "Epoch 9:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9048%\n",
      "Validation set's best loss: 0.036586\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "Epoch 10:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.6429%\n",
      "Validation set's best loss: 0.036586\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "Epoch 11:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9048%\n",
      "Validation set's best loss: 0.036586\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "Epoch 12:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.5952%\n",
      "Validation set's best loss: 0.036586\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "Epoch 13:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.8095%\n",
      "Validation set's best loss: 0.036586\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "Epoch 14:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9048%\n",
      "Validation set's best loss: 0.036586\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "Epoch 15:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9048%\n",
      "Validation set's best loss: 0.036586\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "Epoch 16:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.9048%\n",
      "Validation set's best loss: 0.036586\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "Epoch 17:\n",
      "Last batch's accuracy: 100.0000%\n",
      "Validation set's accuracy: 98.8810%\n",
      "Validation set's best loss: 0.036586\n",
      "Early stopping!\n",
      "4593.042272567749\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for x_batch, y_batch in shuffle_batch(x_train, y_train, batch_size):\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            tfs.run(training_op, feed_dict = {x: x_batch, y: y_batch, training: True})\n",
    "            \n",
    "            if i % check_interval == 0:\n",
    "                \n",
    "                loss_val = loss.eval(feed_dict = {x: x_valid, y: y_valid})\n",
    "                \n",
    "                if loss_val < best_loss_val:\n",
    "                    \n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_parameters()\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    checks_since_last_progress +=1\n",
    "\n",
    "        acc_batch = accuracy.eval(feed_dict = {x: x_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict = {x: x_valid, y: y_valid})\n",
    "        \n",
    "        print(\n",
    "            \"Epoch {}:\\nLast batch's accuracy: {:.4f}%\\nValidation set's accuracy: {:.4f}%\\nValidation set's best loss: {:.6f}\".format(\n",
    "                epoch,\n",
    "                acc_batch*100,\n",
    "                acc_val*100,\n",
    "                best_loss_val\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if checks_since_last_progress > max_checks_wo_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "    if best_model_params:\n",
    "        restore_model_parameters(best_model_params)\n",
    "        \n",
    "    save_path = saver.save(tfs, \"./MNIST_CNN\")\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as tfs:\n",
    "#    saver.restore(tfs, \"./MNIST_CNN\")\n",
    "#    pred_val = predictions.eval(feed_dict = {x: x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
